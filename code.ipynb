{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eca32f6c-203e-4713-b617-28e95f021482",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2efd8be2-91f6-4a32-a7de-0328a487690e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"dataset.csv\", encoding='latin1')\n",
    "data = data[['sentiment', 'text']]\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e07f830-81c1-432a-8d35-b3d78e24b6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>WTF MY BATTERY WAS 31% ONE SECOND AGO AND NOW ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@apple Contact sync between Yosemite and iOS8 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>WARNING IF YOU BUY AN IPHONE 5S UNLOCKED FROM ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>@Apple, For the love of GAWD, CENTER the '1'on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>i get the storage almost full notification lit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               text\n",
       "0         1  WTF MY BATTERY WAS 31% ONE SECOND AGO AND NOW ...\n",
       "1         1  @apple Contact sync between Yosemite and iOS8 ...\n",
       "2         1  WARNING IF YOU BUY AN IPHONE 5S UNLOCKED FROM ...\n",
       "3         1  @Apple, For the love of GAWD, CENTER the '1'on...\n",
       "4         1  i get the storage almost full notification lit..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26e23a9a-7451-4236-b67d-bfd638ffafc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "3    2162\n",
       "1    1219\n",
       "5     423\n",
       "4      82\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiment'].replace('not_relevant',4,inplace=True)\n",
    "data[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d35da7b-de9f-4a26-8a78-9f81ac85ac58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='sentiment', ylabel='count'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"sentiment\",data=data, palette=\"Set3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56bea8e3-ee38-40f0-96c6-8827c8d37b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                       wtf battery one second ago wtf\n",
       "1    contact sync yosemite io seriously screwed use...\n",
       "2    warning buy iphone unlocked iphone use verizon...\n",
       "3    love gawd center damn calendar app fixed back ...\n",
       "4    get storage almost full notification literally...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_tweet(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub(r'http\\S+|www\\S+|https\\S+', '', tweet)\n",
    "    tweet = re.sub(r'@[A-Za-z0-9_]+', '', tweet)\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    tweet = re.sub(r'\\W', ' ', tweet)\n",
    "    tweet = re.sub(r'\\d+', '', tweet)\n",
    "    tweet = re.sub(r'\\S+@\\S+', '', tweet)\n",
    "    tokens = word_tokenize(tweet)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    preprocessed_tweet = ' '.join(tokens)\n",
    "    return preprocessed_tweet\n",
    "\n",
    "preprocessed_tweets = [preprocess_tweet(tweet) for tweet in data['text']]\n",
    "data['text'] = preprocessed_tweets\n",
    "data['text'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0afc56f6-13c4-4195-90be-0963cb00b88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"sentiment\"]=data[\"sentiment\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1405f496-da1b-48a3-85ab-96c3e14a70bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['text']\n",
    "y = data['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7aa28270-cbd4-4707-9172-e87e5669f598",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_train_counts = count_vectorizer.fit_transform(X_train)\n",
    "X_test_counts = count_vectorizer.transform(X_test)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "ngram_vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
    "X_train_ngrams = ngram_vectorizer.fit_transform(X_train)\n",
    "X_test_ngrams = ngram_vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9ef96ac8-63fa-4370-b198-fcba09c12ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "classifiers = {\n",
    "    'Naïve Bayes': MultinomialNB(),\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'SVM': SVC(),\n",
    "    'Perceptron': Perceptron()\n",
    "}\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "classifiers['Logistic Regression'] = log_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c6d13f98-38a0-42fc-ab55-4e5e60db9651",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "results = {}\n",
    "averages=['macro','micro']\n",
    "for avg in averages:\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        clf.fit(X_train_counts, y_train)\n",
    "        y_pred = clf.predict(X_test_counts)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average=avg,zero_division=1)\n",
    "        recall = recall_score(y_test, y_pred, average=avg)\n",
    "        f1 = f1_score(y_test, y_pred, average=avg)\n",
    "        results[(clf_name,avg)]= {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1': f1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "04c2279c-e564-4499-8ea5-00dfa4fe2365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Feature Extraction Technique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naïve Bayes</th>\n",
       "      <th>macro</th>\n",
       "      <td>0.717224</td>\n",
       "      <td>0.477087</td>\n",
       "      <td>0.441477</td>\n",
       "      <td>0.445683</td>\n",
       "      <td>Bag of words based on raw counts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>macro</th>\n",
       "      <td>0.749357</td>\n",
       "      <td>0.531413</td>\n",
       "      <td>0.453415</td>\n",
       "      <td>0.469815</td>\n",
       "      <td>Bag of words based on raw counts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <th>macro</th>\n",
       "      <td>0.727506</td>\n",
       "      <td>0.519248</td>\n",
       "      <td>0.431936</td>\n",
       "      <td>0.449526</td>\n",
       "      <td>Bag of words based on raw counts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <th>macro</th>\n",
       "      <td>0.735219</td>\n",
       "      <td>0.814025</td>\n",
       "      <td>0.419849</td>\n",
       "      <td>0.433445</td>\n",
       "      <td>Bag of words based on raw counts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <th>macro</th>\n",
       "      <td>0.728792</td>\n",
       "      <td>0.521163</td>\n",
       "      <td>0.453980</td>\n",
       "      <td>0.472327</td>\n",
       "      <td>Bag of words based on raw counts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naïve Bayes</th>\n",
       "      <th>micro</th>\n",
       "      <td>0.717224</td>\n",
       "      <td>0.717224</td>\n",
       "      <td>0.717224</td>\n",
       "      <td>0.717224</td>\n",
       "      <td>Bag of words based on raw counts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>micro</th>\n",
       "      <td>0.749357</td>\n",
       "      <td>0.749357</td>\n",
       "      <td>0.749357</td>\n",
       "      <td>0.749357</td>\n",
       "      <td>Bag of words based on raw counts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <th>micro</th>\n",
       "      <td>0.737789</td>\n",
       "      <td>0.737789</td>\n",
       "      <td>0.737789</td>\n",
       "      <td>0.737789</td>\n",
       "      <td>Bag of words based on raw counts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <th>micro</th>\n",
       "      <td>0.735219</td>\n",
       "      <td>0.735219</td>\n",
       "      <td>0.735219</td>\n",
       "      <td>0.735219</td>\n",
       "      <td>Bag of words based on raw counts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <th>micro</th>\n",
       "      <td>0.728792</td>\n",
       "      <td>0.728792</td>\n",
       "      <td>0.728792</td>\n",
       "      <td>0.728792</td>\n",
       "      <td>Bag of words based on raw counts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Accuracy  Precision    Recall        F1  \\\n",
       "Naïve Bayes         macro  0.717224   0.477087  0.441477  0.445683   \n",
       "Logistic Regression macro  0.749357   0.531413  0.453415  0.469815   \n",
       "Random Forest       macro  0.727506   0.519248  0.431936  0.449526   \n",
       "SVM                 macro  0.735219   0.814025  0.419849  0.433445   \n",
       "Perceptron          macro  0.728792   0.521163  0.453980  0.472327   \n",
       "Naïve Bayes         micro  0.717224   0.717224  0.717224  0.717224   \n",
       "Logistic Regression micro  0.749357   0.749357  0.749357  0.749357   \n",
       "Random Forest       micro  0.737789   0.737789  0.737789  0.737789   \n",
       "SVM                 micro  0.735219   0.735219  0.735219  0.735219   \n",
       "Perceptron          micro  0.728792   0.728792  0.728792  0.728792   \n",
       "\n",
       "                               Feature Extraction Technique  \n",
       "Naïve Bayes         macro  Bag of words based on raw counts  \n",
       "Logistic Regression macro  Bag of words based on raw counts  \n",
       "Random Forest       macro  Bag of words based on raw counts  \n",
       "SVM                 macro  Bag of words based on raw counts  \n",
       "Perceptron          macro  Bag of words based on raw counts  \n",
       "Naïve Bayes         micro  Bag of words based on raw counts  \n",
       "Logistic Regression micro  Bag of words based on raw counts  \n",
       "Random Forest       micro  Bag of words based on raw counts  \n",
       "SVM                 micro  Bag of words based on raw counts  \n",
       "Perceptron          micro  Bag of words based on raw counts  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "# I am Transposing the DataFrame to have classifiers as rows and metrics as columns\n",
    "results_df = results_df.T\n",
    "results_df['Feature Extraction Technique']='Bag of words based on raw counts'\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "73e981cb-e966-4409-b907-df5379854dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_tfidf = {}\n",
    "averages=['macro','micro']\n",
    "for avg in averages:\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        clf.fit(X_train_tfidf, y_train)\n",
    "        y_pred = clf.predict(X_test_tfidf)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average=avg,zero_division=1)\n",
    "        recall = recall_score(y_test, y_pred, average=avg)\n",
    "        f1 = f1_score(y_test, y_pred, average=avg)\n",
    "        results_tfidf[(clf_name,avg)] = {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f3ade90f-3987-44a4-b7b0-f1b3e1e27463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Feature Extraction Technique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naïve Bayes</th>\n",
       "      <th>macro</th>\n",
       "      <td>0.736504</td>\n",
       "      <td>0.838757</td>\n",
       "      <td>0.415240</td>\n",
       "      <td>0.417829</td>\n",
       "      <td>Bag of words based on TfIDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>macro</th>\n",
       "      <td>0.754499</td>\n",
       "      <td>0.816921</td>\n",
       "      <td>0.445115</td>\n",
       "      <td>0.460718</td>\n",
       "      <td>Bag of words based on TfIDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <th>macro</th>\n",
       "      <td>0.721080</td>\n",
       "      <td>0.511903</td>\n",
       "      <td>0.416928</td>\n",
       "      <td>0.431221</td>\n",
       "      <td>Bag of words based on TfIDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <th>macro</th>\n",
       "      <td>0.749357</td>\n",
       "      <td>0.837212</td>\n",
       "      <td>0.437398</td>\n",
       "      <td>0.453886</td>\n",
       "      <td>Bag of words based on TfIDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <th>macro</th>\n",
       "      <td>0.688946</td>\n",
       "      <td>0.483669</td>\n",
       "      <td>0.460989</td>\n",
       "      <td>0.467899</td>\n",
       "      <td>Bag of words based on TfIDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naïve Bayes</th>\n",
       "      <th>micro</th>\n",
       "      <td>0.736504</td>\n",
       "      <td>0.736504</td>\n",
       "      <td>0.736504</td>\n",
       "      <td>0.736504</td>\n",
       "      <td>Bag of words based on TfIDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>micro</th>\n",
       "      <td>0.754499</td>\n",
       "      <td>0.754499</td>\n",
       "      <td>0.754499</td>\n",
       "      <td>0.754499</td>\n",
       "      <td>Bag of words based on TfIDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <th>micro</th>\n",
       "      <td>0.719794</td>\n",
       "      <td>0.719794</td>\n",
       "      <td>0.719794</td>\n",
       "      <td>0.719794</td>\n",
       "      <td>Bag of words based on TfIDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <th>micro</th>\n",
       "      <td>0.749357</td>\n",
       "      <td>0.749357</td>\n",
       "      <td>0.749357</td>\n",
       "      <td>0.749357</td>\n",
       "      <td>Bag of words based on TfIDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <th>micro</th>\n",
       "      <td>0.688946</td>\n",
       "      <td>0.688946</td>\n",
       "      <td>0.688946</td>\n",
       "      <td>0.688946</td>\n",
       "      <td>Bag of words based on TfIDF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Accuracy  Precision    Recall        F1  \\\n",
       "Naïve Bayes         macro  0.736504   0.838757  0.415240  0.417829   \n",
       "Logistic Regression macro  0.754499   0.816921  0.445115  0.460718   \n",
       "Random Forest       macro  0.721080   0.511903  0.416928  0.431221   \n",
       "SVM                 macro  0.749357   0.837212  0.437398  0.453886   \n",
       "Perceptron          macro  0.688946   0.483669  0.460989  0.467899   \n",
       "Naïve Bayes         micro  0.736504   0.736504  0.736504  0.736504   \n",
       "Logistic Regression micro  0.754499   0.754499  0.754499  0.754499   \n",
       "Random Forest       micro  0.719794   0.719794  0.719794  0.719794   \n",
       "SVM                 micro  0.749357   0.749357  0.749357  0.749357   \n",
       "Perceptron          micro  0.688946   0.688946  0.688946  0.688946   \n",
       "\n",
       "                          Feature Extraction Technique  \n",
       "Naïve Bayes         macro  Bag of words based on TfIDF  \n",
       "Logistic Regression macro  Bag of words based on TfIDF  \n",
       "Random Forest       macro  Bag of words based on TfIDF  \n",
       "SVM                 macro  Bag of words based on TfIDF  \n",
       "Perceptron          macro  Bag of words based on TfIDF  \n",
       "Naïve Bayes         micro  Bag of words based on TfIDF  \n",
       "Logistic Regression micro  Bag of words based on TfIDF  \n",
       "Random Forest       micro  Bag of words based on TfIDF  \n",
       "SVM                 micro  Bag of words based on TfIDF  \n",
       "Perceptron          micro  Bag of words based on TfIDF  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df2 = pd.DataFrame(results_tfidf)\n",
    "results_df2 = results_df2.T\n",
    "results_df2['Feature Extraction Technique']='Bag of words based on TfIDF'\n",
    "results_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4141e717-30df-4e61-8d8a-430f39d0ca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ngrams = {}\n",
    "averages=['macro','micro']\n",
    "for avg in averages:\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        clf.fit(X_train_ngrams, y_train)\n",
    "        y_pred = clf.predict(X_test_ngrams)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average=avg,zero_division=1)\n",
    "        recall = recall_score(y_test, y_pred, average=avg)\n",
    "        f1 = f1_score(y_test, y_pred, average=avg)\n",
    "        results_ngrams[(clf_name,avg)] = {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9de51c00-88b1-4a63-b772-58e81aa13e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Feature Extraction Technique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naïve Bayes</th>\n",
       "      <th>macro</th>\n",
       "      <td>0.739075</td>\n",
       "      <td>0.759537</td>\n",
       "      <td>0.433275</td>\n",
       "      <td>0.435328</td>\n",
       "      <td>ngrams (unigrams, bigrams, trigrams)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>macro</th>\n",
       "      <td>0.742931</td>\n",
       "      <td>0.531160</td>\n",
       "      <td>0.440159</td>\n",
       "      <td>0.455817</td>\n",
       "      <td>ngrams (unigrams, bigrams, trigrams)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <th>macro</th>\n",
       "      <td>0.712082</td>\n",
       "      <td>0.771039</td>\n",
       "      <td>0.416281</td>\n",
       "      <td>0.433935</td>\n",
       "      <td>ngrams (unigrams, bigrams, trigrams)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <th>macro</th>\n",
       "      <td>0.691517</td>\n",
       "      <td>0.847945</td>\n",
       "      <td>0.379794</td>\n",
       "      <td>0.389889</td>\n",
       "      <td>ngrams (unigrams, bigrams, trigrams)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <th>macro</th>\n",
       "      <td>0.728792</td>\n",
       "      <td>0.510926</td>\n",
       "      <td>0.465705</td>\n",
       "      <td>0.482563</td>\n",
       "      <td>ngrams (unigrams, bigrams, trigrams)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naïve Bayes</th>\n",
       "      <th>micro</th>\n",
       "      <td>0.739075</td>\n",
       "      <td>0.739075</td>\n",
       "      <td>0.739075</td>\n",
       "      <td>0.739075</td>\n",
       "      <td>ngrams (unigrams, bigrams, trigrams)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>micro</th>\n",
       "      <td>0.742931</td>\n",
       "      <td>0.742931</td>\n",
       "      <td>0.742931</td>\n",
       "      <td>0.742931</td>\n",
       "      <td>ngrams (unigrams, bigrams, trigrams)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <th>micro</th>\n",
       "      <td>0.713368</td>\n",
       "      <td>0.713368</td>\n",
       "      <td>0.713368</td>\n",
       "      <td>0.713368</td>\n",
       "      <td>ngrams (unigrams, bigrams, trigrams)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <th>micro</th>\n",
       "      <td>0.691517</td>\n",
       "      <td>0.691517</td>\n",
       "      <td>0.691517</td>\n",
       "      <td>0.691517</td>\n",
       "      <td>ngrams (unigrams, bigrams, trigrams)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <th>micro</th>\n",
       "      <td>0.728792</td>\n",
       "      <td>0.728792</td>\n",
       "      <td>0.728792</td>\n",
       "      <td>0.728792</td>\n",
       "      <td>ngrams (unigrams, bigrams, trigrams)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Accuracy  Precision    Recall        F1  \\\n",
       "Naïve Bayes         macro  0.739075   0.759537  0.433275  0.435328   \n",
       "Logistic Regression macro  0.742931   0.531160  0.440159  0.455817   \n",
       "Random Forest       macro  0.712082   0.771039  0.416281  0.433935   \n",
       "SVM                 macro  0.691517   0.847945  0.379794  0.389889   \n",
       "Perceptron          macro  0.728792   0.510926  0.465705  0.482563   \n",
       "Naïve Bayes         micro  0.739075   0.739075  0.739075  0.739075   \n",
       "Logistic Regression micro  0.742931   0.742931  0.742931  0.742931   \n",
       "Random Forest       micro  0.713368   0.713368  0.713368  0.713368   \n",
       "SVM                 micro  0.691517   0.691517  0.691517  0.691517   \n",
       "Perceptron          micro  0.728792   0.728792  0.728792  0.728792   \n",
       "\n",
       "                                   Feature Extraction Technique  \n",
       "Naïve Bayes         macro  ngrams (unigrams, bigrams, trigrams)  \n",
       "Logistic Regression macro  ngrams (unigrams, bigrams, trigrams)  \n",
       "Random Forest       macro  ngrams (unigrams, bigrams, trigrams)  \n",
       "SVM                 macro  ngrams (unigrams, bigrams, trigrams)  \n",
       "Perceptron          macro  ngrams (unigrams, bigrams, trigrams)  \n",
       "Naïve Bayes         micro  ngrams (unigrams, bigrams, trigrams)  \n",
       "Logistic Regression micro  ngrams (unigrams, bigrams, trigrams)  \n",
       "Random Forest       micro  ngrams (unigrams, bigrams, trigrams)  \n",
       "SVM                 micro  ngrams (unigrams, bigrams, trigrams)  \n",
       "Perceptron          micro  ngrams (unigrams, bigrams, trigrams)  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df3 = pd.DataFrame(results_ngrams)\n",
    "results_df3 = results_df3.T\n",
    "results_df3['Feature Extraction Technique']='ngrams (unigrams, bigrams, trigrams)'\n",
    "results_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1b45ef0f-d4f8-436d-949e-c9f722a3d3da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Feature Extraction Technique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naïve Bayes</th>\n",
       "      <th>macro</th>\n",
       "      <td>0.717224</td>\n",
       "      <td>0.477087</td>\n",
       "      <td>0.441477</td>\n",
       "      <td>0.445683</td>\n",
       "      <td>Bag of words based on raw counts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>macro</th>\n",
       "      <td>0.749357</td>\n",
       "      <td>0.531413</td>\n",
       "      <td>0.453415</td>\n",
       "      <td>0.469815</td>\n",
       "      <td>Bag of words based on raw counts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <th>macro</th>\n",
       "      <td>0.727506</td>\n",
       "      <td>0.519248</td>\n",
       "      <td>0.431936</td>\n",
       "      <td>0.449526</td>\n",
       "      <td>Bag of words based on raw counts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <th>macro</th>\n",
       "      <td>0.735219</td>\n",
       "      <td>0.814025</td>\n",
       "      <td>0.419849</td>\n",
       "      <td>0.433445</td>\n",
       "      <td>Bag of words based on raw counts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <th>macro</th>\n",
       "      <td>0.728792</td>\n",
       "      <td>0.521163</td>\n",
       "      <td>0.453980</td>\n",
       "      <td>0.472327</td>\n",
       "      <td>Bag of words based on raw counts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naïve Bayes</th>\n",
       "      <th>micro</th>\n",
       "      <td>0.717224</td>\n",
       "      <td>0.717224</td>\n",
       "      <td>0.717224</td>\n",
       "      <td>0.717224</td>\n",
       "      <td>Bag of words based on raw counts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>micro</th>\n",
       "      <td>0.749357</td>\n",
       "      <td>0.749357</td>\n",
       "      <td>0.749357</td>\n",
       "      <td>0.749357</td>\n",
       "      <td>Bag of words based on raw counts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <th>micro</th>\n",
       "      <td>0.737789</td>\n",
       "      <td>0.737789</td>\n",
       "      <td>0.737789</td>\n",
       "      <td>0.737789</td>\n",
       "      <td>Bag of words based on raw counts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <th>micro</th>\n",
       "      <td>0.735219</td>\n",
       "      <td>0.735219</td>\n",
       "      <td>0.735219</td>\n",
       "      <td>0.735219</td>\n",
       "      <td>Bag of words based on raw counts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <th>micro</th>\n",
       "      <td>0.728792</td>\n",
       "      <td>0.728792</td>\n",
       "      <td>0.728792</td>\n",
       "      <td>0.728792</td>\n",
       "      <td>Bag of words based on raw counts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naïve Bayes</th>\n",
       "      <th>macro</th>\n",
       "      <td>0.736504</td>\n",
       "      <td>0.838757</td>\n",
       "      <td>0.415240</td>\n",
       "      <td>0.417829</td>\n",
       "      <td>Bag of words based on TfIDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>macro</th>\n",
       "      <td>0.754499</td>\n",
       "      <td>0.816921</td>\n",
       "      <td>0.445115</td>\n",
       "      <td>0.460718</td>\n",
       "      <td>Bag of words based on TfIDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <th>macro</th>\n",
       "      <td>0.721080</td>\n",
       "      <td>0.511903</td>\n",
       "      <td>0.416928</td>\n",
       "      <td>0.431221</td>\n",
       "      <td>Bag of words based on TfIDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <th>macro</th>\n",
       "      <td>0.749357</td>\n",
       "      <td>0.837212</td>\n",
       "      <td>0.437398</td>\n",
       "      <td>0.453886</td>\n",
       "      <td>Bag of words based on TfIDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <th>macro</th>\n",
       "      <td>0.688946</td>\n",
       "      <td>0.483669</td>\n",
       "      <td>0.460989</td>\n",
       "      <td>0.467899</td>\n",
       "      <td>Bag of words based on TfIDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naïve Bayes</th>\n",
       "      <th>micro</th>\n",
       "      <td>0.736504</td>\n",
       "      <td>0.736504</td>\n",
       "      <td>0.736504</td>\n",
       "      <td>0.736504</td>\n",
       "      <td>Bag of words based on TfIDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>micro</th>\n",
       "      <td>0.754499</td>\n",
       "      <td>0.754499</td>\n",
       "      <td>0.754499</td>\n",
       "      <td>0.754499</td>\n",
       "      <td>Bag of words based on TfIDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <th>micro</th>\n",
       "      <td>0.719794</td>\n",
       "      <td>0.719794</td>\n",
       "      <td>0.719794</td>\n",
       "      <td>0.719794</td>\n",
       "      <td>Bag of words based on TfIDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <th>micro</th>\n",
       "      <td>0.749357</td>\n",
       "      <td>0.749357</td>\n",
       "      <td>0.749357</td>\n",
       "      <td>0.749357</td>\n",
       "      <td>Bag of words based on TfIDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <th>micro</th>\n",
       "      <td>0.688946</td>\n",
       "      <td>0.688946</td>\n",
       "      <td>0.688946</td>\n",
       "      <td>0.688946</td>\n",
       "      <td>Bag of words based on TfIDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naïve Bayes</th>\n",
       "      <th>macro</th>\n",
       "      <td>0.739075</td>\n",
       "      <td>0.759537</td>\n",
       "      <td>0.433275</td>\n",
       "      <td>0.435328</td>\n",
       "      <td>ngrams (unigrams, bigrams, trigrams)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>macro</th>\n",
       "      <td>0.742931</td>\n",
       "      <td>0.531160</td>\n",
       "      <td>0.440159</td>\n",
       "      <td>0.455817</td>\n",
       "      <td>ngrams (unigrams, bigrams, trigrams)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <th>macro</th>\n",
       "      <td>0.712082</td>\n",
       "      <td>0.771039</td>\n",
       "      <td>0.416281</td>\n",
       "      <td>0.433935</td>\n",
       "      <td>ngrams (unigrams, bigrams, trigrams)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <th>macro</th>\n",
       "      <td>0.691517</td>\n",
       "      <td>0.847945</td>\n",
       "      <td>0.379794</td>\n",
       "      <td>0.389889</td>\n",
       "      <td>ngrams (unigrams, bigrams, trigrams)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <th>macro</th>\n",
       "      <td>0.728792</td>\n",
       "      <td>0.510926</td>\n",
       "      <td>0.465705</td>\n",
       "      <td>0.482563</td>\n",
       "      <td>ngrams (unigrams, bigrams, trigrams)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naïve Bayes</th>\n",
       "      <th>micro</th>\n",
       "      <td>0.739075</td>\n",
       "      <td>0.739075</td>\n",
       "      <td>0.739075</td>\n",
       "      <td>0.739075</td>\n",
       "      <td>ngrams (unigrams, bigrams, trigrams)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>micro</th>\n",
       "      <td>0.742931</td>\n",
       "      <td>0.742931</td>\n",
       "      <td>0.742931</td>\n",
       "      <td>0.742931</td>\n",
       "      <td>ngrams (unigrams, bigrams, trigrams)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <th>micro</th>\n",
       "      <td>0.713368</td>\n",
       "      <td>0.713368</td>\n",
       "      <td>0.713368</td>\n",
       "      <td>0.713368</td>\n",
       "      <td>ngrams (unigrams, bigrams, trigrams)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <th>micro</th>\n",
       "      <td>0.691517</td>\n",
       "      <td>0.691517</td>\n",
       "      <td>0.691517</td>\n",
       "      <td>0.691517</td>\n",
       "      <td>ngrams (unigrams, bigrams, trigrams)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <th>micro</th>\n",
       "      <td>0.728792</td>\n",
       "      <td>0.728792</td>\n",
       "      <td>0.728792</td>\n",
       "      <td>0.728792</td>\n",
       "      <td>ngrams (unigrams, bigrams, trigrams)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Accuracy  Precision    Recall        F1  \\\n",
       "Naïve Bayes         macro  0.717224   0.477087  0.441477  0.445683   \n",
       "Logistic Regression macro  0.749357   0.531413  0.453415  0.469815   \n",
       "Random Forest       macro  0.727506   0.519248  0.431936  0.449526   \n",
       "SVM                 macro  0.735219   0.814025  0.419849  0.433445   \n",
       "Perceptron          macro  0.728792   0.521163  0.453980  0.472327   \n",
       "Naïve Bayes         micro  0.717224   0.717224  0.717224  0.717224   \n",
       "Logistic Regression micro  0.749357   0.749357  0.749357  0.749357   \n",
       "Random Forest       micro  0.737789   0.737789  0.737789  0.737789   \n",
       "SVM                 micro  0.735219   0.735219  0.735219  0.735219   \n",
       "Perceptron          micro  0.728792   0.728792  0.728792  0.728792   \n",
       "Naïve Bayes         macro  0.736504   0.838757  0.415240  0.417829   \n",
       "Logistic Regression macro  0.754499   0.816921  0.445115  0.460718   \n",
       "Random Forest       macro  0.721080   0.511903  0.416928  0.431221   \n",
       "SVM                 macro  0.749357   0.837212  0.437398  0.453886   \n",
       "Perceptron          macro  0.688946   0.483669  0.460989  0.467899   \n",
       "Naïve Bayes         micro  0.736504   0.736504  0.736504  0.736504   \n",
       "Logistic Regression micro  0.754499   0.754499  0.754499  0.754499   \n",
       "Random Forest       micro  0.719794   0.719794  0.719794  0.719794   \n",
       "SVM                 micro  0.749357   0.749357  0.749357  0.749357   \n",
       "Perceptron          micro  0.688946   0.688946  0.688946  0.688946   \n",
       "Naïve Bayes         macro  0.739075   0.759537  0.433275  0.435328   \n",
       "Logistic Regression macro  0.742931   0.531160  0.440159  0.455817   \n",
       "Random Forest       macro  0.712082   0.771039  0.416281  0.433935   \n",
       "SVM                 macro  0.691517   0.847945  0.379794  0.389889   \n",
       "Perceptron          macro  0.728792   0.510926  0.465705  0.482563   \n",
       "Naïve Bayes         micro  0.739075   0.739075  0.739075  0.739075   \n",
       "Logistic Regression micro  0.742931   0.742931  0.742931  0.742931   \n",
       "Random Forest       micro  0.713368   0.713368  0.713368  0.713368   \n",
       "SVM                 micro  0.691517   0.691517  0.691517  0.691517   \n",
       "Perceptron          micro  0.728792   0.728792  0.728792  0.728792   \n",
       "\n",
       "                                   Feature Extraction Technique  \n",
       "Naïve Bayes         macro      Bag of words based on raw counts  \n",
       "Logistic Regression macro      Bag of words based on raw counts  \n",
       "Random Forest       macro      Bag of words based on raw counts  \n",
       "SVM                 macro      Bag of words based on raw counts  \n",
       "Perceptron          macro      Bag of words based on raw counts  \n",
       "Naïve Bayes         micro      Bag of words based on raw counts  \n",
       "Logistic Regression micro      Bag of words based on raw counts  \n",
       "Random Forest       micro      Bag of words based on raw counts  \n",
       "SVM                 micro      Bag of words based on raw counts  \n",
       "Perceptron          micro      Bag of words based on raw counts  \n",
       "Naïve Bayes         macro           Bag of words based on TfIDF  \n",
       "Logistic Regression macro           Bag of words based on TfIDF  \n",
       "Random Forest       macro           Bag of words based on TfIDF  \n",
       "SVM                 macro           Bag of words based on TfIDF  \n",
       "Perceptron          macro           Bag of words based on TfIDF  \n",
       "Naïve Bayes         micro           Bag of words based on TfIDF  \n",
       "Logistic Regression micro           Bag of words based on TfIDF  \n",
       "Random Forest       micro           Bag of words based on TfIDF  \n",
       "SVM                 micro           Bag of words based on TfIDF  \n",
       "Perceptron          micro           Bag of words based on TfIDF  \n",
       "Naïve Bayes         macro  ngrams (unigrams, bigrams, trigrams)  \n",
       "Logistic Regression macro  ngrams (unigrams, bigrams, trigrams)  \n",
       "Random Forest       macro  ngrams (unigrams, bigrams, trigrams)  \n",
       "SVM                 macro  ngrams (unigrams, bigrams, trigrams)  \n",
       "Perceptron          macro  ngrams (unigrams, bigrams, trigrams)  \n",
       "Naïve Bayes         micro  ngrams (unigrams, bigrams, trigrams)  \n",
       "Logistic Regression micro  ngrams (unigrams, bigrams, trigrams)  \n",
       "Random Forest       micro  ngrams (unigrams, bigrams, trigrams)  \n",
       "SVM                 micro  ngrams (unigrams, bigrams, trigrams)  \n",
       "Perceptron          micro  ngrams (unigrams, bigrams, trigrams)  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([results_df,results_df2,results_df3], axis=0)\n",
    "df.to_csv('Report.csv', index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906ff6d1-bfd6-41c9-ae36-d8a9b77ee7dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cb72d1-a124-4309-b5d3-7ec1a463a0b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
